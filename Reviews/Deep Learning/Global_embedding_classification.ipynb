{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fadd2a8-921a-4d95-b729-a4c9671de902",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Random\n",
    "\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch\n",
    "using Flux: crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bae69-e5d4-413a-9d3d-2c2c053b0ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed73af7-62e8-4aca-99e1-6f17e66b5e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600-element Vector{Float64}:\n",
       " 5.0\n",
       " 5.0\n",
       " 1.0\n",
       " 5.0\n",
       " 5.0\n",
       " 4.0\n",
       " 4.0\n",
       " 5.0\n",
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 1.0\n",
       " 5.0\n",
       " â‹®\n",
       " 4.0\n",
       " 4.0\n",
       " 5.0\n",
       " 5.0\n",
       " 5.0\n",
       " 5.0\n",
       " 5.0\n",
       " 5.0\n",
       " 1.0\n",
       " 3.0\n",
       " 4.0\n",
       " 1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "data = CSV.read(\"fin_reviews2.csv\", DataFrame)\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "Random.seed!(123)\n",
    "\n",
    "# Determine the split ratios\n",
    "train_ratio = 0.9\n",
    "validation_ratio = 0.04\n",
    "test_ratio = 0.06\n",
    "\n",
    "# Calculate the split indices\n",
    "n_samples = nrow(data)\n",
    "train_index = Int(round(train_ratio * n_samples))\n",
    "validation_index = Int(round((train_ratio + validation_ratio) * n_samples))\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle!(data)\n",
    "\n",
    "# Split the data\n",
    "train_data = data[1:train_index, :]\n",
    "validation_data = data[train_index+1:validation_index, :]\n",
    "test_data = data[validation_index+1:end, :]\n",
    "\n",
    "# Prepare the matrices for the models\n",
    "X_train = Matrix(train_data[:, 8:end])\n",
    "y_train = train_data.stars\n",
    "X_valid = Matrix(validation_data[:, 8:end])\n",
    "y_valid = validation_data.stars\n",
    "X_test = Matrix(test_data[:, 8:end])\n",
    "y_test = test_data.stars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689d24b2-6531-4dd2-b6fa-27f2739dc2f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `param` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `param` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[3]:1"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "using XGBoost\n",
    "\n",
    "# Convert labels to zero-based for XGBoost\n",
    "y_train_xgb = y_train .- 1\n",
    "y_valid_xgb = y_valid .- 1\n",
    "y_test_xgb = y_test .- 1\n",
    "\n",
    "# Hyperparameter search setup\n",
    "best_score = -Inf\n",
    "best_params = nothing\n",
    "\n",
    "dtrain = DMatrix(X_train, label=y_train_xgb)\n",
    "dvalid = DMatrix(X_valid, label=y_valid_xgb)\n",
    "dtest = DMatrix(X_test, label=y_test_xgb)\n",
    "\n",
    "for eta in [0.01, 0.001]\n",
    "    for max_depth in [1, 3, 6, 9]\n",
    "        for num_round in [100, 200,300]\n",
    "            param = (\n",
    "                \"eta\" => eta, \n",
    "                \"max_depth\" => max_depth, \n",
    "                \"objective\" => \"multi:softprob\", \n",
    "                \"num_class\" => 5,\n",
    "                \"eval_metric\" => \"mlogloss\" \n",
    "            )\n",
    "            model = xgboost(dtrain; eta=eta,max_depth=max_depth, num_round=num_round)\n",
    "            preds = round.(predict(model, dvalid))\n",
    "           \n",
    "            accuracy = sum(preds.== y_valid_xgb) / length(y_valid_xgb)\n",
    "            if accuracy > best_score\n",
    "                best_score = accuracy\n",
    "                best_params = (param, num_round)\n",
    "                @info \"Hyperparameters: $param, Num Rounds: $num_round, Accuracy: $accuracy\"\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_param, best_num_round = best_params\n",
    "final_model = xgboost(dtrain; best_param, num_round=best_num_round)\n",
    "preds = round.(predict(final_model, dtest))\n",
    "\n",
    "accuracy = sum(preds .== y_test_xgb) / length(y_test_xgb)\n",
    "println(\"XGBoost Accuracy on Test Set: \", accuracy)\n",
    "\n",
    "using JLD2\n",
    "@save \"xgboost_model.jld2\" own_final\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0864499b-7e59-4b65-aede-f999dec31e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy = 0.6166666666666667\n",
      "Epoch 2: Validation Accuracy = 0.6291666666666667\n",
      "Epoch 3: Validation Accuracy = 0.6279166666666667\n",
      "Epoch 4: Validation Accuracy = 0.6041666666666666\n",
      "Epoch 5: Validation Accuracy = 0.6291666666666667\n",
      "Epoch 6: Validation Accuracy = 0.6316666666666667\n",
      "Epoch 7: Validation Accuracy = 0.6233333333333333\n",
      "Epoch 8: Validation Accuracy = 0.6245833333333334\n",
      "Epoch 9: Validation Accuracy = 0.6279166666666667\n",
      "Epoch 10: Validation Accuracy = 0.6308333333333334\n",
      "Epoch 11: Validation Accuracy = 0.6241666666666666\n",
      "Epoch 12: Validation Accuracy = 0.64\n",
      "Epoch 13: Validation Accuracy = 0.6304166666666666\n",
      "Epoch 14: Validation Accuracy = 0.6295833333333334\n",
      "Epoch 15: Validation Accuracy = 0.6316666666666667\n",
      "Epoch 16: Validation Accuracy = 0.6375\n",
      "Epoch 17: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 18: Validation Accuracy = 0.6329166666666667\n",
      "Epoch 19: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 20: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 21: Validation Accuracy = 0.6083333333333333\n",
      "Epoch 22: Validation Accuracy = 0.6325\n",
      "Epoch 23: Validation Accuracy = 0.6370833333333333\n",
      "MLP Accuracy on Test Set: 0.6380555555555556\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch, crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA\n",
    "using Random\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "# Transpose and move X_train to the correct device\n",
    "X_train1 = transpose(X_train) |> device\n",
    "batch_size = 32\n",
    "X_valid1 = transpose(X_valid) |> device\n",
    "X_test1 = transpose(X_test) |> device\n",
    "\n",
    "# Convert y_train to onehot encoding and move to the correct device\n",
    "y_train1 = Flux.onehotbatch(y_train, 1:5) |> device\n",
    "y_valid1 = Flux.onehotbatch(y_valid, 1:5) |> device\n",
    "y_test1 = Flux.onehotbatch(y_test, 1:5) |> device\n",
    "\n",
    "# Create DataLoader and move to the correct device\n",
    "loader = Flux.DataLoader((X_train1, y_train1), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "# Define the MLP model and move to the correct device\n",
    "model = Chain(\n",
    "    Dense(300, 128, relu),\n",
    "    Dense(128, 64, relu),\n",
    "    Dense(64, 5),\n",
    "    softmax\n",
    ") |> device\n",
    "\n",
    "# Define the loss function\n",
    "loss(model, X, y) = Flux.crossentropy(model(X), y)\n",
    "\n",
    "# Setup the optimizer\n",
    "opt = Flux.setup(Adam(0.004), model)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "accuracy(X, y) = mean(onecold(model(X)) .== onecold(y))\n",
    "\n",
    "# Training with validation\n",
    "best_val_accuracy = 0.0\n",
    "best_model_params = nothing\n",
    "last_imp=0\n",
    "for epoch in 1:491\n",
    "    Flux.train!(loss, model, loader, opt)\n",
    "    val_accuracy = accuracy(X_valid1, y_valid1)\n",
    "    println(\"Epoch $epoch: Validation Accuracy = $val_accuracy\")\n",
    "    last_imp+=1\n",
    "    if val_accuracy > best_val_accuracy\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model_params = cpu(Flux.state(model))\n",
    "        BSON.@save \"bestmlp3layersown.bson\" model_params\n",
    "        last_imp=0\n",
    "    end\n",
    "    if last_imp>10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy(X_test1, y_test1)\n",
    "println(\"MLP Accuracy on Test Set: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e152fec-f129-4042-9029-44603ceaa75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy = 0.61\n",
      "Epoch 2: Validation Accuracy = 0.61625\n",
      "Epoch 3: Validation Accuracy = 0.6183333333333333\n",
      "Epoch 4: Validation Accuracy = 0.6195833333333334\n",
      "Epoch 5: Validation Accuracy = 0.6225\n",
      "Epoch 6: Validation Accuracy = 0.625\n",
      "Epoch 7: Validation Accuracy = 0.6254166666666666\n",
      "Epoch 8: Validation Accuracy = 0.6279166666666667\n",
      "Epoch 9: Validation Accuracy = 0.6266666666666667\n",
      "Epoch 10: Validation Accuracy = 0.6283333333333333\n",
      "Epoch 11: Validation Accuracy = 0.62875\n",
      "Epoch 12: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 13: Validation Accuracy = 0.6279166666666667\n",
      "Epoch 14: Validation Accuracy = 0.62875\n",
      "Epoch 15: Validation Accuracy = 0.6275\n",
      "Epoch 16: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 17: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 18: Validation Accuracy = 0.6325\n",
      "Epoch 19: Validation Accuracy = 0.63125\n",
      "Epoch 20: Validation Accuracy = 0.6283333333333333\n",
      "Epoch 21: Validation Accuracy = 0.6325\n",
      "Epoch 22: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 23: Validation Accuracy = 0.6295833333333334\n",
      "Epoch 24: Validation Accuracy = 0.6279166666666667\n",
      "Epoch 25: Validation Accuracy = 0.6316666666666667\n",
      "Epoch 26: Validation Accuracy = 0.635\n",
      "Epoch 27: Validation Accuracy = 0.6333333333333333\n",
      "Epoch 28: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 29: Validation Accuracy = 0.635\n",
      "Epoch 30: Validation Accuracy = 0.63\n",
      "Epoch 31: Validation Accuracy = 0.6329166666666667\n",
      "Epoch 32: Validation Accuracy = 0.63375\n",
      "Epoch 33: Validation Accuracy = 0.6316666666666667\n",
      "Epoch 34: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 35: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 36: Validation Accuracy = 0.6320833333333333\n",
      "Epoch 37: Validation Accuracy = 0.63125\n",
      "Epoch 38: Validation Accuracy = 0.6333333333333333\n",
      "Epoch 39: Validation Accuracy = 0.635\n",
      "Epoch 40: Validation Accuracy = 0.6329166666666667\n",
      "Epoch 41: Validation Accuracy = 0.6345833333333334\n",
      "Epoch 42: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 43: Validation Accuracy = 0.6358333333333334\n",
      "Epoch 44: Validation Accuracy = 0.63375\n",
      "Epoch 45: Validation Accuracy = 0.63125\n",
      "Epoch 46: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 47: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 48: Validation Accuracy = 0.6329166666666667\n",
      "Epoch 49: Validation Accuracy = 0.63125\n",
      "Epoch 50: Validation Accuracy = 0.6320833333333333\n",
      "Epoch 51: Validation Accuracy = 0.6325\n",
      "Epoch 52: Validation Accuracy = 0.63625\n",
      "Epoch 53: Validation Accuracy = 0.6333333333333333\n",
      "Epoch 54: Validation Accuracy = 0.6320833333333333\n",
      "Epoch 55: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 56: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 57: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 58: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 59: Validation Accuracy = 0.6316666666666667\n",
      "Epoch 60: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 61: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 62: Validation Accuracy = 0.6329166666666667\n",
      "Epoch 63: Validation Accuracy = 0.6320833333333333\n",
      "Epoch 64: Validation Accuracy = 0.6325\n",
      "Epoch 65: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 66: Validation Accuracy = 0.63625\n",
      "Epoch 67: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 68: Validation Accuracy = 0.6291666666666667\n",
      "Epoch 69: Validation Accuracy = 0.63875\n",
      "Epoch 70: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 71: Validation Accuracy = 0.6316666666666667\n",
      "Epoch 72: Validation Accuracy = 0.6375\n",
      "Epoch 73: Validation Accuracy = 0.6333333333333333\n",
      "Epoch 74: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 75: Validation Accuracy = 0.6333333333333333\n",
      "Epoch 76: Validation Accuracy = 0.6329166666666667\n",
      "Epoch 77: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 78: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 79: Validation Accuracy = 0.6345833333333334\n",
      "Epoch 80: Validation Accuracy = 0.6375\n",
      "Epoch 81: Validation Accuracy = 0.64125\n",
      "Epoch 82: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 83: Validation Accuracy = 0.63875\n",
      "Epoch 84: Validation Accuracy = 0.6341666666666667\n",
      "Epoch 85: Validation Accuracy = 0.64\n",
      "Epoch 86: Validation Accuracy = 0.6425\n",
      "Epoch 87: Validation Accuracy = 0.6358333333333334\n",
      "Epoch 88: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 89: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 90: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 91: Validation Accuracy = 0.63625\n",
      "Epoch 92: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 93: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 94: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 95: Validation Accuracy = 0.63875\n",
      "Epoch 96: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 97: Validation Accuracy = 0.64375\n",
      "Epoch 98: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 99: Validation Accuracy = 0.64\n",
      "Epoch 100: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 101: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 102: Validation Accuracy = 0.64\n",
      "Epoch 103: Validation Accuracy = 0.63875\n",
      "Epoch 104: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 105: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 106: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 107: Validation Accuracy = 0.64625\n",
      "Epoch 108: Validation Accuracy = 0.6425\n",
      "Epoch 109: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 110: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 111: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 112: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 113: Validation Accuracy = 0.63625\n",
      "Epoch 114: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 115: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 116: Validation Accuracy = 0.6375\n",
      "Epoch 117: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 118: Validation Accuracy = 0.63875\n",
      "Epoch 119: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 120: Validation Accuracy = 0.64375\n",
      "Epoch 121: Validation Accuracy = 0.64375\n",
      "Epoch 122: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 123: Validation Accuracy = 0.6425\n",
      "Epoch 124: Validation Accuracy = 0.6425\n",
      "Epoch 125: Validation Accuracy = 0.6375\n",
      "Epoch 126: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 127: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 128: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 129: Validation Accuracy = 0.64\n",
      "Epoch 130: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 131: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 132: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 133: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 134: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 135: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 136: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 137: Validation Accuracy = 0.6425\n",
      "Epoch 138: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 139: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 140: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 141: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 142: Validation Accuracy = 0.64125\n",
      "Epoch 143: Validation Accuracy = 0.6358333333333334\n",
      "Epoch 144: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 145: Validation Accuracy = 0.6425\n",
      "Epoch 146: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 147: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 148: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 149: Validation Accuracy = 0.63875\n",
      "Epoch 150: Validation Accuracy = 0.64125\n",
      "Epoch 151: Validation Accuracy = 0.6425\n",
      "Epoch 152: Validation Accuracy = 0.64375\n",
      "Epoch 153: Validation Accuracy = 0.6425\n",
      "Epoch 154: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 155: Validation Accuracy = 0.64375\n",
      "Epoch 156: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 157: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 158: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 159: Validation Accuracy = 0.64\n",
      "Epoch 160: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 161: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 162: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 163: Validation Accuracy = 0.63875\n",
      "Epoch 164: Validation Accuracy = 0.64125\n",
      "Epoch 165: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 166: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 167: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 168: Validation Accuracy = 0.64125\n",
      "Epoch 169: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 170: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 171: Validation Accuracy = 0.64\n",
      "Epoch 172: Validation Accuracy = 0.645\n",
      "Epoch 173: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 174: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 175: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 176: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 177: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 178: Validation Accuracy = 0.64125\n",
      "Epoch 179: Validation Accuracy = 0.6425\n",
      "Epoch 180: Validation Accuracy = 0.6425\n",
      "Epoch 181: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 182: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 183: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 184: Validation Accuracy = 0.645\n",
      "Epoch 185: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 186: Validation Accuracy = 0.64125\n",
      "Epoch 187: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 188: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 189: Validation Accuracy = 0.64125\n",
      "Epoch 190: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 191: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 192: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 193: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 194: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 195: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 196: Validation Accuracy = 0.6375\n",
      "Epoch 197: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 198: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 199: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 200: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 201: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 202: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 203: Validation Accuracy = 0.64375\n",
      "Epoch 204: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 205: Validation Accuracy = 0.6425\n",
      "Epoch 206: Validation Accuracy = 0.64\n",
      "Epoch 207: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 208: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 209: Validation Accuracy = 0.6354166666666666\n",
      "Epoch 210: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 211: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 212: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 213: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 214: Validation Accuracy = 0.6375\n",
      "Epoch 215: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 216: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 217: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 218: Validation Accuracy = 0.64375\n",
      "Epoch 219: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 220: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 221: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 222: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 223: Validation Accuracy = 0.645\n",
      "Epoch 224: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 225: Validation Accuracy = 0.6466666666666666\n",
      "Epoch 226: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 227: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 228: Validation Accuracy = 0.6425\n",
      "Epoch 229: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 230: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 231: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 232: Validation Accuracy = 0.64625\n",
      "Epoch 233: Validation Accuracy = 0.645\n",
      "Epoch 234: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 235: Validation Accuracy = 0.64\n",
      "Epoch 236: Validation Accuracy = 0.64375\n",
      "Epoch 237: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 238: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 239: Validation Accuracy = 0.6425\n",
      "Epoch 240: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 241: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 242: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 243: Validation Accuracy = 0.64625\n",
      "Epoch 244: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 245: Validation Accuracy = 0.64375\n",
      "Epoch 246: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 247: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 248: Validation Accuracy = 0.64625\n",
      "Epoch 249: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 250: Validation Accuracy = 0.64625\n",
      "Epoch 251: Validation Accuracy = 0.645\n",
      "Epoch 252: Validation Accuracy = 0.6425\n",
      "Epoch 253: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 254: Validation Accuracy = 0.6425\n",
      "Epoch 255: Validation Accuracy = 0.6475\n",
      "Epoch 256: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 257: Validation Accuracy = 0.6425\n",
      "Epoch 258: Validation Accuracy = 0.645\n",
      "Epoch 259: Validation Accuracy = 0.6466666666666666\n",
      "Epoch 260: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 261: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 262: Validation Accuracy = 0.6425\n",
      "Epoch 263: Validation Accuracy = 0.64625\n",
      "Epoch 264: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 265: Validation Accuracy = 0.64625\n",
      "Epoch 266: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 267: Validation Accuracy = 0.645\n",
      "Epoch 268: Validation Accuracy = 0.645\n",
      "Epoch 269: Validation Accuracy = 0.64125\n",
      "Epoch 270: Validation Accuracy = 0.64375\n",
      "Epoch 271: Validation Accuracy = 0.64125\n",
      "Epoch 272: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 273: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 274: Validation Accuracy = 0.6475\n",
      "Epoch 275: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 276: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 277: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 278: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 279: Validation Accuracy = 0.6425\n",
      "Epoch 280: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 281: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 282: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 283: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 284: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 285: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 286: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 287: Validation Accuracy = 0.6475\n",
      "Epoch 288: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 289: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 290: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 291: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 292: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 293: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 294: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 295: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 296: Validation Accuracy = 0.6479166666666667\n",
      "Epoch 297: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 298: Validation Accuracy = 0.64125\n",
      "Epoch 299: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 300: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 301: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 302: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 303: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 304: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 305: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 306: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 307: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 308: Validation Accuracy = 0.6425\n",
      "Epoch 309: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 310: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 311: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 312: Validation Accuracy = 0.6466666666666666\n",
      "Epoch 313: Validation Accuracy = 0.6395833333333333\n",
      "Epoch 314: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 315: Validation Accuracy = 0.6483333333333333\n",
      "Epoch 316: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 317: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 318: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 319: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 320: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 321: Validation Accuracy = 0.645\n",
      "Epoch 322: Validation Accuracy = 0.64125\n",
      "Epoch 323: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 324: Validation Accuracy = 0.64625\n",
      "Epoch 325: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 326: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 327: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 328: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 329: Validation Accuracy = 0.63875\n",
      "Epoch 330: Validation Accuracy = 0.6429166666666667\n",
      "Epoch 331: Validation Accuracy = 0.6454166666666666\n",
      "Epoch 332: Validation Accuracy = 0.645\n",
      "Epoch 333: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 334: Validation Accuracy = 0.6470833333333333\n",
      "Epoch 335: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 336: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 337: Validation Accuracy = 0.64125\n",
      "Epoch 338: Validation Accuracy = 0.645\n",
      "Epoch 339: Validation Accuracy = 0.64625\n",
      "Epoch 340: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 341: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 342: Validation Accuracy = 0.6445833333333333\n",
      "Epoch 343: Validation Accuracy = 0.64125\n",
      "Epoch 344: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 345: Validation Accuracy = 0.6491666666666667\n",
      "Epoch 346: Validation Accuracy = 0.64\n",
      "Epoch 347: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 348: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 349: Validation Accuracy = 0.6404166666666666\n",
      "Epoch 350: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 351: Validation Accuracy = 0.6420833333333333\n",
      "Epoch 352: Validation Accuracy = 0.6425\n",
      "Epoch 353: Validation Accuracy = 0.6458333333333334\n",
      "Epoch 354: Validation Accuracy = 0.645\n",
      "Epoch 355: Validation Accuracy = 0.6441666666666667\n",
      "Epoch 356: Validation Accuracy = 0.645\n",
      "Epoch 357: Validation Accuracy = 0.6408333333333334\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] synchronize (repeats 2 times)",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\CUDA\\XUdwt\\lib\\cudadrv\\synchronization.jl:194 [inlined]",
      "  [2] (::CUDA.var\"#1098#1099\"{Bool, Vector{Bool}, Int64, CuArray{Bool, 1, CUDA.Mem.DeviceBuffer}, Int64, Int64})()",
      "    @ CUDA C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\CUDA\\XUdwt\\src\\array.jl:606",
      "  [3] #context!#954",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\CUDA\\XUdwt\\lib\\cudadrv\\state.jl:170 [inlined]",
      "  [4] context!",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\CUDA\\XUdwt\\lib\\cudadrv\\state.jl:165 [inlined]",
      "  [5] unsafe_copyto!(dest::Vector{Bool}, doffs::Int64, src::CuArray{Bool, 1, CUDA.Mem.DeviceBuffer}, soffs::Int64, n::Int64)",
      "    @ CUDA C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\CUDA\\XUdwt\\src\\array.jl:602",
      "  [6] copyto!",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\CUDA\\XUdwt\\src\\array.jl:555 [inlined]",
      "  [7] getindex",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:50 [inlined]",
      "  [8] scalar_getindex(::CuArray{Bool, 1, CUDA.Mem.DeviceBuffer})",
      "    @ GPUArrays C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:34",
      "  [9] _getindex",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:17 [inlined]",
      " [10] getindex",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:15 [inlined]",
      " [11] macro expansion",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArraysCore\\GMsgk\\src\\GPUArraysCore.jl:210 [inlined]",
      " [12] _mapreduce(f::typeof(identity), op::typeof(&), As::CuArray{Bool, 1, CUDA.Mem.DeviceBuffer}; dims::Colon, init::Nothing)",
      "    @ GPUArrays C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\mapreduce.jl:71",
      " [13] _mapreduce",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\mapreduce.jl:33 [inlined]",
      " [14] mapreduce",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\mapreduce.jl:28 [inlined]",
      " [15] all",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\mapreduce.jl:78 [inlined]",
      " [16] checkindex",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:139 [inlined]",
      " [17] checkbounds_indices (repeats 2 times)",
      "    @ .\\abstractarray.jl:728 [inlined]",
      " [18] checkbounds",
      "    @ .\\abstractarray.jl:681 [inlined]",
      " [19] checkbounds(::LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, ::Base.Slice{Base.OneTo{Int64}}, ::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer})",
      "    @ Base .\\abstractarray.jl:702",
      " [20] vectorized_getindex!(::CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, ::LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, ::Base.Slice{Base.OneTo{Int64}}, ::Vararg{Any})",
      "    @ GPUArrays C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:70",
      " [21] _unsafe_getindex!",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\GPUArrays\\OqrUV\\src\\host\\indexing.jl:157 [inlined]",
      " [22] _unsafe_getindex",
      "    @ .\\multidimensional.jl:903 [inlined]",
      " [23] _getindex",
      "    @ .\\multidimensional.jl:889 [inlined]",
      " [24] getindex",
      "    @ .\\abstractarray.jl:1291 [inlined]",
      " [25] getobs(A::LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, idx::Vector{Int64})",
      "    @ MLUtils C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\observation.jl:161",
      " [26] #7",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\observation.jl:201 [inlined]",
      " [27] map",
      "    @ .\\tuple.jl:292 [inlined]",
      " [28] getobs",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\observation.jl:201 [inlined]",
      " [29] getobs",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\obsview.jl:187 [inlined]",
      " [30] _getbatch(A::MLUtils.BatchView{Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, MLUtils.ObsView{Tuple{LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Vector{Int64}}, Val{nothing}}, obsindices::UnitRange{Int64})",
      "    @ MLUtils C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\batchview.jl:154",
      " [31] getindex",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\batchview.jl:139 [inlined]",
      " [32] getobs",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\observation.jl:110 [inlined]",
      " [33] getobs(data::MLUtils.BatchView{Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, MLUtils.ObsView{Tuple{LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Vector{Int64}}, Val{nothing}}, idx::Int64)",
      "    @ MLUtils C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\SimpleTraits\\l1ZsK\\src\\SimpleTraits.jl:331",
      " [34] (::MLUtils.var\"#41#43\")(i::Int64)",
      "    @ MLUtils .\\none:0",
      " [35] iterate",
      "    @ .\\generator.jl:47 [inlined]",
      " [36] iterate(::MLUtils.DataLoader{Tuple{LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Random._GLOBAL_RNG, Val{nothing}}, ::Tuple{Base.Generator{UnitRange{Int64}, MLUtils.var\"#41#43\"}, Int64})",
      "    @ MLUtils C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\MLUtils\\LmmaQ\\src\\eachobs.jl:179",
      " [37] iterate",
      "    @ .\\iterators.jl:206 [inlined]",
      " [38] macro expansion",
      "    @ C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\ProgressLogging\\6KXlp\\src\\ProgressLogging.jl:328 [inlined]",
      " [39] train!(loss::Function, model::Chain{Tuple{Dense{typeof(relu), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(relu), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, typeof(softmax)}}, data::MLUtils.DataLoader{Tuple{LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Random._GLOBAL_RNG, Val{nothing}}, opt::@NamedTuple{layers::Tuple{@NamedTuple{weight::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, bias::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Ïƒ::Tuple{}}, @NamedTuple{weight::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, bias::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Ïƒ::Tuple{}}, @NamedTuple{weight::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, bias::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Ïƒ::Tuple{}}, Tuple{}}}; cb::Nothing)",
      "    @ Flux.Train C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\Flux\\Wz6D4\\src\\train.jl:105",
      " [40] train!(loss::Function, model::Chain{Tuple{Dense{typeof(relu), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(relu), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, typeof(softmax)}}, data::MLUtils.DataLoader{Tuple{LinearAlgebra.Transpose{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, Random._GLOBAL_RNG, Val{nothing}}, opt::@NamedTuple{layers::Tuple{@NamedTuple{weight::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, bias::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Ïƒ::Tuple{}}, @NamedTuple{weight::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, bias::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Ïƒ::Tuple{}}, @NamedTuple{weight::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, bias::Optimisers.Leaf{Optimisers.AdaGrad, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Ïƒ::Tuple{}}, Tuple{}}})",
      "    @ Flux.Train C:\\Users\\UÅ¼ytkownik\\.julia\\packages\\Flux\\Wz6D4\\src\\train.jl:102",
      " [41] top-level scope",
      "    @ .\\In[5]:56"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch, crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA\n",
    "using Random\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "# Transpose and move X_train to the correct device\n",
    "X_train1 = transpose(X_train) |> device\n",
    "batch_size = 32\n",
    "X_valid1 = transpose(X_valid) |> device\n",
    "X_test1 = transpose(X_test) |> device\n",
    "\n",
    "# Convert y_train to onehot encoding and move to the correct device\n",
    "y_train1 = Flux.onehotbatch(y_train, 1:5) |> device\n",
    "y_valid1 = Flux.onehotbatch(y_valid, 1:5) |> device\n",
    "y_test1 = Flux.onehotbatch(y_test, 1:5) |> device\n",
    "\n",
    "# Create DataLoader and move to the correct device\n",
    "loader = Flux.DataLoader((X_train1, y_train1), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "# Define the MLP model and move to the correct device\n",
    "model = Chain(\n",
    "    Dense(300, 128, relu),\n",
    "    Dense(128, 64, relu),\n",
    "    Dense(64, 5),\n",
    "    softmax\n",
    ") |> device\n",
    "\n",
    "# Define the loss function\n",
    "loss(model, X, y) = Flux.crossentropy(model(X), y)\n",
    "\n",
    "# Setup the optimizer\n",
    "opt = Flux.setup(AdaGrad(0.004), model)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "accuracy(X, y) = mean(onecold(model(X)) .== onecold(y))\n",
    "\n",
    "# Training with validation\n",
    "best_val_accuracy = 0.0\n",
    "best_model_params = nothing\n",
    "last_imp=0\n",
    "for epoch in 1:491\n",
    "    Flux.train!(loss, model, loader, opt)\n",
    "    val_accuracy = accuracy(X_valid1, y_valid1)\n",
    "    println(\"Epoch $epoch: Validation Accuracy = $val_accuracy\")\n",
    "      last_imp+=1\n",
    "      if val_accuracy > best_val_accuracy\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model_params = cpu(Flux.state(model))\n",
    "        BSON.@save \"bestmlp3layersownada.bson\" model_params   \n",
    "        last_imp=0\n",
    "    end\n",
    "    if last_imp>10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy(X_test1, y_test1)\n",
    "println(\"MLP Accuracy on Test Set: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d42345d-ef60-443d-bf83-bf01287d369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy = 0.6216666666666667\n",
      "Epoch 2: Validation Accuracy = 0.6225\n",
      "Epoch 3: Validation Accuracy = 0.6166666666666667\n",
      "Epoch 4: Validation Accuracy = 0.6345833333333334\n",
      "Epoch 5: Validation Accuracy = 0.60875\n",
      "Epoch 6: Validation Accuracy = 0.59875\n",
      "Epoch 7: Validation Accuracy = 0.6325\n",
      "Epoch 8: Validation Accuracy = 0.62625\n",
      "Epoch 9: Validation Accuracy = 0.6291666666666667\n",
      "Epoch 10: Validation Accuracy = 0.6195833333333334\n",
      "Epoch 11: Validation Accuracy = 0.6325\n",
      "Epoch 12: Validation Accuracy = 0.6095833333333334\n",
      "Epoch 13: Validation Accuracy = 0.62625\n",
      "Epoch 14: Validation Accuracy = 0.6275\n",
      "Epoch 15: Validation Accuracy = 0.6329166666666667\n",
      "MLP Accuracy on Test Set: 0.6366666666666667\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch, crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA\n",
    "using Random\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "# Transpose and move X_train to the correct device\n",
    "X_train1 = transpose(X_train) |> device\n",
    "batch_size = 32\n",
    "X_valid1 = transpose(X_valid) |> device\n",
    "X_test1 = transpose(X_test) |> device\n",
    "\n",
    "# Convert y_train to onehot encoding and move to the correct device\n",
    "y_train1 = Flux.onehotbatch(y_train, 1:5) |> device\n",
    "y_valid1 = Flux.onehotbatch(y_valid, 1:5) |> device\n",
    "y_test1 = Flux.onehotbatch(y_test, 1:5) |> device\n",
    "\n",
    "# Create DataLoader and move to the correct device\n",
    "loader = Flux.DataLoader((X_train1, y_train1), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "# Define the MLP model and move to the correct device\n",
    "model = Chain(\n",
    "    Dense(300, 128, tanh),\n",
    "    Dense(128, 64, tanh),\n",
    "    Dense(64, 5),\n",
    "    softmax\n",
    ") |> device\n",
    "\n",
    "# Define the loss function\n",
    "loss(model, X, y) = Flux.crossentropy(model(X), y)\n",
    "\n",
    "# Setup the optimizer\n",
    "opt = Flux.setup(NADAM(0.004), model)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "accuracy(X, y) = mean(onecold(model(X)) .== onecold(y))\n",
    "\n",
    "# Training with validation\n",
    "best_val_accuracy = 0.0\n",
    "best_model_params = nothing\n",
    "last_imp=0\n",
    "for epoch in 1:491\n",
    "    Flux.train!(loss, model, loader, opt)\n",
    "    val_accuracy = accuracy(X_valid1, y_valid1)\n",
    "    println(\"Epoch $epoch: Validation Accuracy = $val_accuracy\")\n",
    "    last_imp+=1\n",
    "    if val_accuracy > best_val_accuracy\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model_params = cpu(Flux.state(model))\n",
    "        BSON.@save \"bestmlp3layersownnestor.bson\" model_params\n",
    "           last_imp=0\n",
    "    end\n",
    "    if last_imp>10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy(X_test1, y_test1)\n",
    "println(\"MLP Accuracy on Test Set: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a025adbf-9d6d-42b7-bb06-36f3bfac8318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy = 0.6045833333333334\n",
      "Epoch 2: Validation Accuracy = 0.6120833333333333\n",
      "Epoch 3: Validation Accuracy = 0.6266666666666667\n",
      "Epoch 4: Validation Accuracy = 0.63125\n",
      "Epoch 5: Validation Accuracy = 0.6325\n",
      "Epoch 6: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 7: Validation Accuracy = 0.6145833333333334\n",
      "Epoch 8: Validation Accuracy = 0.63\n",
      "Epoch 9: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 10: Validation Accuracy = 0.63125\n",
      "Epoch 11: Validation Accuracy = 0.6358333333333334\n",
      "Epoch 12: Validation Accuracy = 0.63625\n",
      "Epoch 13: Validation Accuracy = 0.6425\n",
      "Epoch 14: Validation Accuracy = 0.6425\n",
      "Epoch 15: Validation Accuracy = 0.6254166666666666\n",
      "Epoch 16: Validation Accuracy = 0.6433333333333333\n",
      "Epoch 17: Validation Accuracy = 0.6366666666666667\n",
      "Epoch 18: Validation Accuracy = 0.6325\n",
      "Epoch 19: Validation Accuracy = 0.6333333333333333\n",
      "Epoch 20: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 21: Validation Accuracy = 0.63875\n",
      "Epoch 22: Validation Accuracy = 0.62875\n",
      "Epoch 23: Validation Accuracy = 0.6304166666666666\n",
      "Epoch 24: Validation Accuracy = 0.6408333333333334\n",
      "Epoch 25: Validation Accuracy = 0.6391666666666667\n",
      "Epoch 26: Validation Accuracy = 0.6133333333333333\n",
      "Epoch 27: Validation Accuracy = 0.61875\n",
      "MLP Accuracy on Test Set: 0.6419444444444444\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch, crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA\n",
    "using Random\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "# Transpose and move X_train to the correct device\n",
    "X_train1 = transpose(X_train) |> device\n",
    "batch_size = 32\n",
    "X_valid1 = transpose(X_valid) |> device\n",
    "X_test1 = transpose(X_test) |> device\n",
    "\n",
    "# Convert y_train to onehot encoding and move to the correct device\n",
    "y_train1 = Flux.onehotbatch(y_train, 1:5) |> device\n",
    "y_valid1 = Flux.onehotbatch(y_valid, 1:5) |> device\n",
    "y_test1 = Flux.onehotbatch(y_test, 1:5) |> device\n",
    "\n",
    "# Create DataLoader and move to the correct device\n",
    "loader = Flux.DataLoader((X_train1, y_train1), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "# Define the MLP model and move to the correct device\n",
    "model= Chain(\n",
    "  Dense(300 => 32, relu),\n",
    "  Dense(32 => 5),\n",
    "  softmax) |> device\n",
    "\n",
    "# Define the loss function\n",
    "loss(model, X, y) = Flux.crossentropy(model(X), y)\n",
    "\n",
    "# Setup the optimizer\n",
    "opt = Flux.setup(Adam(0.004), model)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "accuracy(X, y) = mean(onecold(model(X)) .== onecold(y))\n",
    "\n",
    "# Training with validation\n",
    "best_val_accuracy = 0.0\n",
    "best_model_params = nothing\n",
    "last_imp=0\n",
    "for epoch in 1:491\n",
    "    Flux.train!(loss, model, loader, opt)\n",
    "    val_accuracy = accuracy(X_valid1, y_valid1)\n",
    "    println(\"Epoch $epoch: Validation Accuracy = $val_accuracy\")\n",
    "      last_imp+=1\n",
    "    if val_accuracy > best_val_accuracy\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model_params = cpu(Flux.state(model))\n",
    "        BSON.@save \"simpleownadam.bson\" model_params \n",
    "         last_imp=0\n",
    "    end\n",
    "    if last_imp>10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy(X_test1, y_test1)\n",
    "println(\"MLP Accuracy on Test Set: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60df760e-b1b7-4fcc-b8e7-ac81a7304e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy = 0.5766666666666667\n",
      "Epoch 2: Validation Accuracy = 0.5970833333333333\n",
      "Epoch 3: Validation Accuracy = 0.6058333333333333\n",
      "Epoch 4: Validation Accuracy = 0.61\n",
      "Epoch 5: Validation Accuracy = 0.60875\n",
      "Epoch 6: Validation Accuracy = 0.6125\n",
      "Epoch 7: Validation Accuracy = 0.6154166666666666\n",
      "Epoch 8: Validation Accuracy = 0.6166666666666667\n",
      "Epoch 9: Validation Accuracy = 0.6154166666666666\n",
      "Epoch 10: Validation Accuracy = 0.61375\n",
      "Epoch 11: Validation Accuracy = 0.6179166666666667\n",
      "Epoch 12: Validation Accuracy = 0.6158333333333333\n",
      "Epoch 13: Validation Accuracy = 0.6183333333333333\n",
      "Epoch 14: Validation Accuracy = 0.6175\n",
      "Epoch 15: Validation Accuracy = 0.62\n",
      "Epoch 16: Validation Accuracy = 0.6191666666666666\n",
      "Epoch 17: Validation Accuracy = 0.6216666666666667\n",
      "Epoch 18: Validation Accuracy = 0.6216666666666667\n",
      "Epoch 19: Validation Accuracy = 0.6208333333333333\n",
      "Epoch 20: Validation Accuracy = 0.6216666666666667\n",
      "Epoch 21: Validation Accuracy = 0.6225\n",
      "Epoch 22: Validation Accuracy = 0.6245833333333334\n",
      "Epoch 23: Validation Accuracy = 0.6233333333333333\n",
      "Epoch 24: Validation Accuracy = 0.62625\n",
      "Epoch 25: Validation Accuracy = 0.6220833333333333\n",
      "Epoch 26: Validation Accuracy = 0.6229166666666667\n",
      "Epoch 27: Validation Accuracy = 0.625\n",
      "Epoch 28: Validation Accuracy = 0.62125\n",
      "Epoch 29: Validation Accuracy = 0.625\n",
      "Epoch 30: Validation Accuracy = 0.625\n",
      "Epoch 31: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 32: Validation Accuracy = 0.625\n",
      "Epoch 33: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 34: Validation Accuracy = 0.6245833333333334\n",
      "Epoch 35: Validation Accuracy = 0.6258333333333334\n",
      "MLP Accuracy on Test Set: 0.6369444444444444\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch, crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA\n",
    "using Random\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "# Transpose and move X_train to the correct device\n",
    "X_train1 = transpose(X_train) |> device\n",
    "batch_size = 32\n",
    "X_valid1 = transpose(X_valid) |> device\n",
    "X_test1 = transpose(X_test) |> device\n",
    "\n",
    "# Convert y_train to onehot encoding and move to the correct device\n",
    "y_train1 = Flux.onehotbatch(y_train, 1:5) |> device\n",
    "y_valid1 = Flux.onehotbatch(y_valid, 1:5) |> device\n",
    "y_test1 = Flux.onehotbatch(y_test, 1:5) |> device\n",
    "\n",
    "# Create DataLoader and move to the correct device\n",
    "loader = Flux.DataLoader((X_train1, y_train1), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "# Define the MLP model and move to the correct device\n",
    "model= Chain(\n",
    "  Dense(300 => 32, relu),\n",
    "  Dense(32 => 5),\n",
    "  softmax) |> device\n",
    "\n",
    "# Define the loss function\n",
    "loss(model, X, y) = Flux.crossentropy(model(X), y)\n",
    "\n",
    "# Setup the optimizer\n",
    "opt = Flux.setup(AdaGrad(0.004), model)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "accuracy(X, y) = mean(onecold(model(X)) .== onecold(y))\n",
    "\n",
    "# Training with validation\n",
    "best_val_accuracy = 0.0\n",
    "best_model_params = nothing\n",
    "last_imp=0\n",
    "for epoch in 1:491\n",
    "    Flux.train!(loss, model, loader, opt)\n",
    "    val_accuracy = accuracy(X_valid1, y_valid1)\n",
    "    println(\"Epoch $epoch: Validation Accuracy = $val_accuracy\")\n",
    "      last_imp+=1\n",
    "    if val_accuracy > best_val_accuracy\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model_params = cpu(Flux.state(model))\n",
    "        BSON.@save \"simpleadaown.bson\" model_params \n",
    "        last_imp=0\n",
    "    end\n",
    "    if last_imp>10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy(X_test1, y_test1)\n",
    "println(\"MLP Accuracy on Test Set: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe92f93-5df8-421d-b02e-817793640b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Accuracy = 0.6233333333333333\n",
      "Epoch 2: Validation Accuracy = 0.6204166666666666\n",
      "Epoch 3: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 4: Validation Accuracy = 0.6195833333333334\n",
      "Epoch 5: Validation Accuracy = 0.6375\n",
      "Epoch 6: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 7: Validation Accuracy = 0.6416666666666667\n",
      "Epoch 8: Validation Accuracy = 0.6383333333333333\n",
      "Epoch 9: Validation Accuracy = 0.6258333333333334\n",
      "Epoch 10: Validation Accuracy = 0.6283333333333333\n",
      "Epoch 11: Validation Accuracy = 0.6275\n",
      "Epoch 12: Validation Accuracy = 0.6379166666666667\n",
      "Epoch 13: Validation Accuracy = 0.635\n",
      "Epoch 14: Validation Accuracy = 0.6291666666666667\n",
      "Epoch 15: Validation Accuracy = 0.6304166666666666\n",
      "Epoch 16: Validation Accuracy = 0.6325\n",
      "Epoch 17: Validation Accuracy = 0.6370833333333333\n",
      "Epoch 18: Validation Accuracy = 0.63375\n",
      "MLP Accuracy on Test Set: 0.6433333333333333\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, onehotbatch, crossentropy, throttle, params\n",
    "using Zygote\n",
    "using BSON, JLD2, Statistics\n",
    "using CUDA\n",
    "using Random\n",
    "using Base.Iterators: repeated, partition\n",
    "import StatsBase.sample, StatsBase.Weights\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "# Transpose and move X_train to the correct device\n",
    "X_train1 = transpose(X_train) |> device\n",
    "batch_size = 32\n",
    "X_valid1 = transpose(X_valid) |> device\n",
    "X_test1 = transpose(X_test) |> device\n",
    "\n",
    "# Convert y_train to onehot encoding and move to the correct device\n",
    "y_train1 = Flux.onehotbatch(y_train, 1:5) |> device\n",
    "y_valid1 = Flux.onehotbatch(y_valid, 1:5) |> device\n",
    "y_test1 = Flux.onehotbatch(y_test, 1:5) |> device\n",
    "\n",
    "# Create DataLoader and move to the correct device\n",
    "loader = Flux.DataLoader((X_train1, y_train1), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "# Define the MLP model and move to the correct device\n",
    "model= Chain(\n",
    "  Dense(300 => 32, relu),\n",
    "  Dense(32 => 5),\n",
    "  softmax) |> device\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "loss(model, X, y) = Flux.crossentropy(model(X), y)\n",
    "\n",
    "# Setup the optimizer\n",
    "opt = Flux.setup(NADAM(0.004), model)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "accuracy(X, y) = mean(onecold(model(X)) .== onecold(y))\n",
    "\n",
    "# Training with validation\n",
    "best_val_accuracy = 0.0\n",
    "best_model_params = nothing\n",
    "last_imp=0\n",
    "for epoch in 1:491\n",
    "    Flux.train!(loss, model, loader, opt)\n",
    "    val_accuracy = accuracy(X_valid1, y_valid1)\n",
    "    println(\"Epoch $epoch: Validation Accuracy = $val_accuracy\")\n",
    "      last_imp+=1\n",
    "    if val_accuracy > best_val_accuracy\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model_params = cpu(Flux.state(model))\n",
    "        BSON.@save \"simplesownnestor.bson\" model_params \n",
    "        last_imp=0\n",
    "    end\n",
    "    if last_imp>10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy(X_test1, y_test1)\n",
    "println(\"MLP Accuracy on Test Set: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b0ae7-6afd-4943-bc57-63b499273298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
